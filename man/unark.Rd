% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unark.R
\name{unark}
\alias{unark}
\title{Unarchive a list of compressed tsv files into a databaase}
\usage{
unark(files, db_con, lines = 10000L, ...)
}
\arguments{
\item{files}{vector of filenames to be read in. Must be \code{tsv}
format compressed using \code{bzip2}, \code{gzip}, \code{zip}, or \code{xz} format
at present.}

\item{db_con}{a database src (\code{src_dbi} object from \code{dplyr})}

\item{lines}{number of lines to read in a chunk.}

\item{...}{Arguments passed on to \code{readr::read_tsv}
\describe{
  \item{file}{Either a path to a file, a connection, or literal data
(either a single string or a raw vector).

Files ending in \code{.gz}, \code{.bz2}, \code{.xz}, or \code{.zip} will
be automatically uncompressed. Files starting with \code{http://},
\code{https://}, \code{ftp://}, or \code{ftps://} will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.

Literal data is most useful for examples and tests. It must contain at
least one new line to be recognised as data (instead of a path).}
  \item{quote}{Single character used to quote strings.}
  \item{col_names}{Either \code{TRUE}, \code{FALSE} or a character vector
of column names.

If \code{TRUE}, the first row of the input will be used as the column
names, and will not be included in the data frame. If \code{FALSE}, column
names will be generated automatically: X1, X2, X3 etc.

If \code{col_names} is a character vector, the values will be used as the
names of the columns, and the first row of the input will be read into
the first row of the output data frame.

Missing (\code{NA}) column names will generate a warning, and be filled
in with dummy names \code{X1}, \code{X2} etc. Duplicate column names
will generate a warning and be made unique with a numeric prefix.}
  \item{col_types}{One of \code{NULL}, a \code{\link[=cols]{cols()}} specification, or
a string. See \code{vignette("column-types")} for more details.

If \code{NULL}, all column types will be imputed from the first 1000 rows
on the input. This is convenient (and fast), but not robust. If the
imputation fails, you'll need to supply the correct types yourself.

If a column specification created by \code{\link[=cols]{cols()}}, it must contain
one column specification for each column. If you only want to read a
subset of the columns, use \code{\link[=cols_only]{cols_only()}}.

Alternatively, you can use a compact string representation where each
character represents one column:
c = character, i = integer, n = number, d = double,
l = logical, D = date, T = date time, t = time, ? = guess, or
\code{_}/\code{-} to skip the column.}
  \item{locale}{The locale controls defaults that vary from place to place.
The default locale is US-centric (like R), but you can use
\code{\link[=locale]{locale()}} to create your own locale that controls things like
the default time zone, encoding, decimal mark, big mark, and day/month
names.}
  \item{na}{Character vector of strings to use for missing values. Set this
option to \code{character()} to indicate no missing values.}
  \item{quoted_na}{Should missing values inside quotes be treated as missing
values (the default) or strings.}
  \item{comment}{A string used to identify comments. Any text after the
comment characters will be silently ignored.}
  \item{trim_ws}{Should leading and trailing whitespace be trimmed from
each field before parsing it?}
  \item{skip}{Number of lines to skip before reading data.}
  \item{n_max}{Maximum number of records to read.}
  \item{guess_max}{Maximum number of records to use for guessing column types.}
  \item{progress}{Display a progress bar? By default it will only display
in an interactive session and not while knitting a document. The display
is updated every 50,000 values and will only display if estimated reading
time is 5 seconds or more. The automatic progress bar can be disabled by
setting option \code{readr.show_progress} to \code{FALSE}.}
}}
}
\value{
a database connection (invisibly)
}
\description{
Unarchive a list of compressed tsv files into a databaase
}
\details{
\code{unark} will read in a files in chunks and
write them into a database.  This is essential for processing
large compressed tables which may be too large to read into
memory before writing into a database.  In general, increasing
the \code{lines} parameter will result in a faster total transfer
but require more free memory for working with these larger chunks.
#'
}
\examples{
\donttest{

## Setup: create an archive.
dir <- tempdir() 
db <- dbplyr::nycflights13_sqlite(tempdir())

## database -> .tsv.bz2 
ark(db)

## list all files in archive (full paths)
files <- list.files(dir, "[.tsv.gz]", full.names = TRUE)

## Read archived files into a new database (defaults to sqlite)
new_db <- src_sqlite("local.sqlite", create=TRUE)
unark(files, new_db)

## Prove table is returned successfully.
library(dplyr)
tbl(new_db, "flights")

}
}
